{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо построить модель которая будет классифицировать тексты на позитивные и негативные.\n",
    "\n",
    "В качестве основы взята рекурентная нейронная сеть LSTM (long short-term memory - долгая краткосрочная память). Отличие данной сети от обычной RNN (recurent neiral network) в том, что она способна к обучению долговременным зависимостям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Анализ и подготовка данных__\n",
    "    * __Загрузка и объединение данных.__ Объединим данные добавим целевой признак 'Target' со значениями 1 - негативный текст, 0 - позитивный. Для работы с данными будем пользоваться библиотекой Pandas\n",
    "    * __Очистка текста от лишних знаков и сивмолов.__ Для этого подойдёт библиотека  для регулярных выражений re. Оставим только буквы.\n",
    "    * __Лемматизация текста.__ При помощи библиотеки pymorphy2 будем приводить слова к их нормальной словарной форме:\n",
    "        * для существительных — именительный падеж, единственное число; \n",
    "        * для прилагательных — именительный падеж, единственное число, мужской род; \n",
    "        * для глаголов, причастий, деепричастий — глагол в инфинитиве несовершенного вида.\n",
    "    * __Разделение данных на тренировочную, валидационную. и тестовую__ На тренировочных данных будем учить модель, на валидационных будем проверять хорошо, ли у нас идет обучение. После обучения проверим модель на тестовых данных\n",
    "    * __Векторизация текста.__ Векторизация - это перевод текста в вектор понятный компьютеру. Для этого мы воспользуемся библиотекой PyTorch.\n",
    "2. __Создание модели и тренировка__\n",
    "    * __Создание модели.__ Создадим следующую модель -> Embedding -> LSTM -> Dropout -> Linear -> ReLU -> Linear -> для этого будет использована библиотека PyTorch\n",
    "    * __Создание функций для тренировки.__ Объединим все в одну функцию для запуска тренировки\n",
    "3. __Тестирование модели__\n",
    "    * __Проверка адекватности модели.__ В качестве метрики качества модели выберем F1 score\n",
    "    * __Сохранение модели.__ Сохраним обученную модель для дальнейшего использования\n",
    "    * __Подведение итогов.__ Оценка показателей качества модели, рекомендации по улучшению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Анализ и подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import clearing, tokenizer, DataFrameDataset, LSTM_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Добавление воспроизводимости\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed_all(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Загрузка и объединение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positive_data = pd.read_csv('data/positive.csv', sep='\\n', \n",
    "                            encoding='ANSI', header=None, names=['text'])\n",
    "negative_data = pd.read_csv('data/negative.csv', sep='\\n', \n",
    "                            encoding='ANSI', header=None, names=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"RT @digger2912: \"\"Кто то в углу сидит и погиб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"@irina_dyshkant Вот что значит страшилка :D;;;;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @first_timee хоть я и школота, но поверь, у на...\n",
       "1  Да, все-таки он немного похож на него. Но мой ...\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...\n",
       "3  \"RT @digger2912: \"\"Кто то в углу сидит и погиб...\n",
       "4   \"@irina_dyshkant Вот что значит страшилка :D;;;;"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906762813579264;\"1386325944\";\"dugarchikbell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906818262687744;\"1386325957\";\"nugemycejela\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906858515398656;\"1386325966\";\"4post21\";\"@el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906914437685248;\"1386325980\";\"Poliwake\";\"Же...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906914723295232;\"1386325980\";\"capyvixowe\";\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  408906762813579264;\"1386325944\";\"dugarchikbell...\n",
       "1  408906818262687744;\"1386325957\";\"nugemycejela\"...\n",
       "2  408906858515398656;\"1386325966\";\"4post21\";\"@el...\n",
       "3  408906914437685248;\"1386325980\";\"Poliwake\";\"Же...\n",
       "4  408906914723295232;\"1386325980\";\"capyvixowe\";\"..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# добавим столбец 'target' и объеденим данные\n",
    "positive_data['target'] = 0\n",
    "negative_data['target'] = 1\n",
    "all_data = pd.concat((positive_data, negative_data), \n",
    "                     axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Очистка данных\n",
    "Отчистим и удалим пустые сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отчистим данные\n",
    "all_data['text'] = all_data['text'].apply(clearing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим пропуски и сбросим индексы\n",
    "all_data = all_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на выборки, и одновременно перемешаем. \n",
    "train_val_data, test_data = train_test_split(all_data, train_size=0.8, \n",
    "                                       shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_val_data, train_size=0.75, \n",
    "                                  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162080, 2), (54027, 2), (54027, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создадим классы с текстом и метками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создадим поля для дальнейшей работы с библиотекой PyTorch\n",
    "TEXT = data.Field(tokenize=tokenizer, include_lengths=True,)\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fields = [('text',TEXT), ('label',LABEL)]\n",
    "# Токенизируем наши предложжения, одновременно лемматизируем их.\n",
    "train_ds, val_ds, test_ds = \\\n",
    "        DataFrameDataset.splits(fields, train_df=train_data, \n",
    "                                val_df=val_data, test_df=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['надо', 'создать', 'акк', 'секси', 'нога', 'майкрофт', 'холмс'], 'label': 1}\n",
      "{'text': ['какой', 'мерзкий', 'рожа', 'весь', 'порок', 'на', 'лицо'], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим что получилось\n",
    "print(vars(train_ds[100]))\n",
    "print(vars(test_ds[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Векторизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Максимальный размер словаря возьмем 75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создадим словарь из стренировочного датасета\n",
    "# Примим максимальный размер 75000 слов\n",
    "MAX_VOCAB_SIZE = 75000\n",
    "TEXT.build_vocab(train_ds, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый размер словаря: 73567\n"
     ]
    }
   ],
   "source": [
    "print(f'Итоговый размер словаря: {len(TEXT.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Вывод:\n",
    "1. Данные были загружены и объеденены. Добавлен столбец с классами 'target', в котором 0 - это позитивный текст, 1 - негативный.\n",
    "4. Данные разделены на тренировочную - 60%, валидационную - 20% и тестовую - 20% выборки.\n",
    "2. Проведена лемматизация и отчистка данных. В результате остались только русские символы. Слова приведены к нормальной словоформе.\n",
    "3. Текст был векторизирован. Размер словаря 73567 слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Создание модели и тренировка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание функций для тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "# Создание итератора \n",
    "# Итератор разбивает данные на батчи для последовательной подачи их в модель\n",
    "train_iterator, valid_iterator, test_iterator = \\\n",
    "        data.BucketIterator.splits(\n",
    "    (train_ds, val_ds, test_ds), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Напишем функцию F1 меры: $F1 = \\frac{2\\cdot  precision \\cdot recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(preds, ground_truth):\n",
    "    \"\"\"\n",
    "    Функция высчитыавет F1 score\n",
    "    :param preds: Предсказания модели\n",
    "    :param ground_truth: Метки истинности\n",
    "    :return: значение f1\n",
    "    \"\"\"\n",
    "    # Высчитываем вероятности и округляем их\n",
    "    predictions = torch.round(torch.sigmoid(preds))\n",
    "    # Считаем TP FP и FN\n",
    "    true_positive = ((predictions == 1) * (ground_truth == 1)).sum().item()\n",
    "    false_positive = ((predictions == 1) * (ground_truth == 0)).sum().item()\n",
    "    false_negative = ((predictions == 0) * (ground_truth == 1)).sum().item()\n",
    "    # Исключаем случаи деления на ноль\n",
    "    if true_positive != 0 and false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 1\n",
    "        \n",
    "    if true_positive != 0 and false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 1\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию тренировки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, name):\n",
    "    \"\"\"\n",
    "    Функция для тренировки модели\n",
    "    :param model: Модель\n",
    "    :param iterator: Итератор данных\n",
    "    :param name: Префикс для вывода информации о тренировки\n",
    "    :return: Средний loss и средний score\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # Переведем модель в режим обучения\n",
    "    model.train()\n",
    "    # Создадим панель статуса\n",
    "    with tqdm(total=len(iterator)) as nb:\n",
    "        # Цикл по итератору\n",
    "        for ind, batch in enumerate(iterator):\n",
    "            # Получаем векторизированный текст и его длину\n",
    "            text, text_lengths = batch.text\n",
    "            # Обнулим градиенты у весов модели\n",
    "            optimizer.zero_grad()\n",
    "            # Получим сырые предсказания\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            # Высчитаем loss\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            # Посчитаем F1 score\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            # Посчитаем ошибки для весов\n",
    "            loss.backward()\n",
    "            # Обновим веса\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            description ='T: ' + name + f', loss - {epoch_loss / (ind + 1):.4f}' + f', F1 - {epoch_acc / (ind + 1):.2%}'\n",
    "            # обновим панель статуса\n",
    "            nb.set_description(desc=description, refresh=True)\n",
    "            nb.update()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Функция для предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    \"\"\"\n",
    "    Функция для предсказаний без обученя\n",
    "    :param model: Модель\n",
    "    :param iterator: Итератор\n",
    "    :return: Среднее значение F1 score\n",
    "    \"\"\"\n",
    "    epoch_acc = 0\n",
    "    # Перевод модели в режим предсказания\n",
    "    model.eval()\n",
    "    # Создадим панель статуса\n",
    "    with tqdm(total=len(iterator)) as nb:\n",
    "        # Выключим градиенты\n",
    "        with torch.no_grad():\n",
    "            # Цикл по итератору\n",
    "            for ind, batch in enumerate(iterator):\n",
    "                text, text_lengths = batch.text\n",
    "                predictions = model(text, text_lengths).squeeze(1)\n",
    "                acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "                epoch_acc += acc\n",
    "                nb.set_description(desc=f'V: F1 - {epoch_acc / (ind + 1):.2%}', \n",
    "                                   refresh=True)\n",
    "                nb.update()\n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Тренировка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Опишем саму модель: -> Embedding -> LSTM -> Dropout -> Linear -> ReLU -> Linear ->:\n",
    "    * Embedding - преобразует вектор словаря в вещественный вектор в пространстве с фиксированной невысокой размерностью.\n",
    "    * LSTM - Рекуррентная сеть\n",
    "    * Dropout - Слой позволяющий случайно занулять выходы из предыдущего слоя для регуляризации и лучшего обучения\n",
    "    * Linear - Обычный линейный слой\n",
    "    * ReLU - Нелинейная функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Настройки тренировки\n",
    "num_epochs = 3 # Количество эпох для тренировки\n",
    "learning_rate = 0.001 # Коэффициент обучения\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab) # Входной вектор\n",
    "EMBEDDING_DIM = 200 # Выходной вектор из Embedding\n",
    "HIDDEN_DIM = 256 # Размерность слоев LSTM\n",
    "OUTPUT_DIM = 1 # Выходной вектор\n",
    "N_LAYERS = 2 # Колличество слоев в LSTM\n",
    "BIDIRECTIONAL = True # Двунаправленная LSTM\n",
    "DROPOUT = 0.2 # Процент случайного зануления\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # Паддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим модель\n",
    "model = LSTM_net(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX).to(device)\n",
    "\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В качестве функции ошибки возьмем BCEWithLogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if n == 'embedding.weight'], \n",
    "     'learning_rate': 1e-1\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if n != 'embedding.weight'],\n",
    "     'learning_rate': 1e-3,\n",
    "     'weight_decay': 0.002\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим функцию ошибки и оптимизатор\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(optimizer_grouped_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: Epoch [1 / 3], loss - 0.6144, F1 - 66.09%: 100%|█████████▉| 1266/1267 [01:08<00:00, 19.82it/s]"
     ]
    }
   ],
   "source": [
    "# Процесс тренировки\n",
    "t = time.time()\n",
    "# Будем сохранять историю\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "\n",
    "# Цикл по эпохам\n",
    "for epoch in range(num_epochs):\n",
    "    name = f'Epoch [{epoch + 1} / {num_epochs}]'\n",
    "    # Тренировка\n",
    "    train_loss, train_acc = train(model, train_iterator, name)\n",
    "    # Проверка на валидации\n",
    "    valid_acc = evaluate(model, valid_iterator)\n",
    "    # Запись истории\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)\n",
    "    \n",
    "print(f'time:{time.time()-t:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "1. Для проверки точности модели была взята функция F1 мера.\n",
    "2. В качестве Loss функции взята BCEWithLogLoss\n",
    "3. После обучения модели можно заметить, что значение F1 на тренировочной выборке равняется 79.16%, а на валидационной выборке 71.09%. Модель начала запоминать тренировочные данные. Для решения данной проблемы воможно уменьшить размерность модели. Добавить регуляризации. Взять уже натренированный Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Проверка модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Посмотрим как модель предсказывает на тестовой выборке\n",
    "test_acc = evaluate(model, test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab(vocab, path):\n",
    "    import pickle\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним значения словаря в файл\n",
    "save_vocab(TEXT.vocab, 'vocab.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним веса модели в документ. В дальнейшем можно  будет загрузить уже натренированные веса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним веса модели и параметры с которыми эта модель была обучена\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'input_dim': INPUT_DIM, \n",
    "            'embedding_dim': EMBEDDING_DIM, \n",
    "            'hidden_dim': HIDDEN_DIM, \n",
    "            'output_dim': OUTPUT_DIM, \n",
    "            'n_layers': N_LAYERS, \n",
    "            'bidirectional': BIDIRECTIONAL, \n",
    "            'dropout': DROPOUT, \n",
    "            'pad_idx': PAD_IDX}, 'model.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Вывод:\n",
    "1. Предсказания на тестовой выборке показали F1 меру 71.57%, что соответствует точности на валидационной выборке.\n",
    "2. Был сохранен словарь и веса модели, для дальнейшего их использования с другими данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Выводы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. В ходе работы были подготовлены данные состоящие из позитивных и негативных комментариев. Для начала из данных сформирован один датасет к которому добален признак \"target\" со значениями 0 или 1, где 0 - прзитивный комментарий, 1 - негативный. \n",
    "1. Текст очищен от лишних знаков, слова приведены к нормальной словарной форме. После был составлен словарь, размер которого получился 73567 слов. Данные разделены на тренировочную, валидационную, и тестовую выборки. \n",
    "1. Текст был векторизирован для подачи в подель\n",
    "2. Метрикой качества была выбрана функция F1 мера.\n",
    "2. После трех эпох тренировок модель показала значение F1 на тренировочной выборке равным 79.16%, а на валидационной 71.09%. Что является не большим значением. Для достижения лучшего значения следует рассмотреть рассомтреть следующие варианты:\n",
    "    * Добавить регуляризации модели\n",
    "    * Изменить метод инициализации весов модели\n",
    "    * Сделать разные коэффициенты обучения для различных слоев модели. Например для слоя Embedding увеличить коэффициент обучения.\n",
    "    * Добавление Attention слоя\n",
    "3. На тестовой выборке модель показала знаение F1 - 71.57%.\n",
    "3. Словарь сохранен в файл vocab.txt, а веса модели сохранены в файл model.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}